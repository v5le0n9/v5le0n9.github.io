<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.1.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/logo.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon32.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon16.ico">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-minimal.min.css">
  <script src="/lib/pace/pace.min.js"></script>

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"right","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"default"},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":true,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":"gitalk","storage":true,"lazyload":false,"nav":{"gitalk":{"order":-2}},"activeClass":"gitalk"},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":-1,"unescape":false,"preload":true},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"content.json"};
  </script>

  <meta name="description" content="做机器学习的实验做得我生无可恋，还是先补一下机器学习的几个算法的基本原理再说吧。">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习">
<meta property="og:url" content="http://example.com/posts/498ab7d9.html">
<meta property="og:site_name" content="v5le0n9&#39;s garden">
<meta property="og:description" content="做机器学习的实验做得我生无可恋，还是先补一下机器学习的几个算法的基本原理再说吧。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/posts/498ab7d9/1.1.1.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/1.1.2.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/1.1.3.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/1.1.4.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/1.1.5.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/1.1.6.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/1.3.1.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/1.3.2.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/1.4.1.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/1.5.1.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/1.5.2.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/1.5.3.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/1.5.4.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/1.5.5.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/1.5.6.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/1.5.7.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/1.5.8.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/1.5.9.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/1.5.10.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/1.5.11.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/1.6.1.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/1.6.2.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/1.6.3.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/1.7.1.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/1.7.2.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/1.7.3.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/1.8.1.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/1.8.2.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/1.8.3.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/2.1.1.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/2.1.2.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/2.1.3.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/2.1.4.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/2.1.5.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/2.2.1.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/2.2.2.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/2.2.3.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/2.2.4.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/2.2.5.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/2.2.6.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/2.2.7.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/2.3.1.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/2.3.2.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/2.3.3.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/2.3.4.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/2.3.5.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/2.3.6.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/2.3.7.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/2.3.8.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/2.3.9.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/2.4.1.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/2.4.2.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/2.4.3.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/2.4.4.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/2.4.5.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/2.4.6.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/2.4.7.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/2.4.8.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/2.4.9.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/2.5.1.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/2.5.2.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/2.5.3.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/2.5.4.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/2.5.5.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/2.5.6.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/2.5.7.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/3.1.1.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/3.1.2.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/3.1.3.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/3.1.4.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/3.1.5.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/3.1.6.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/3.1.7.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/3.2.1.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/3.2.2.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/3.2.3.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/3.2.4.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/3.2.5.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/3.2.6.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/3.2.7.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/3.2.8.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/3.2.9.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/3.2.10.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/3.3.1.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/3.3.2.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/3.3.3.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/3.3.4.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/3.3.5.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/3.3.6.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/3.3.7.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/3.3.8.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/3.4.1.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/3.4.2.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/3.4.3.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/3.4.4.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/4.1.3.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/4.1.4.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/4.1.5.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/4.1.1.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/4.1.2.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/4.2.1.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/4.2.2.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/4.3.1.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/4.4.1.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/4.4.2.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/4.4.3.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/4.4.4.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/4.4.5.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/4.4.6.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/4.4.7.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/4.4.8.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/4.5.1.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/4.5.2.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/4.5.3.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/4.6.1.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/4.6.2.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/4.6.3.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/4.6.4.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/4.6.5.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/4.6.6.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/4.6.7.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/4.6.8.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/4.6.9.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.1.1.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.1.2.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.1.3.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.1.4.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.2.1.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.2.2.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.2.3.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.2.4.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.2.5.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.2.6.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.2.7.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.2.8.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.2.9.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.2.10.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.2.11.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.2.12.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.2.13.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.2.14.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.2.17.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.2.15.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.2.16.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.2.18.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.2.20.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.2.21.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.2.22.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.2.23.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.2.24.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.2.25.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.2.26.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.2.19.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.5.1.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.5.2.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.5.3.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.5.4.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.5.5.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.5.6.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.5.7.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.5.8.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.5.9.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.5.10.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.5.11.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.5.12.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.5.13.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.5.14.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.5.15.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.5.16.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.5.17.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.5.18.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.5.19.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.5.20.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.5.21.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.5.22.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.5.23.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.5.24.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.5.25.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.3.1.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.3.2.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.3.2.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.3.4.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.3.5.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.3.6.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.3.7.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.3.8.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.3.9.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.3.10.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.3.11.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.3.12.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.6.1.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.6.2.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.6.3.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.6.4.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.6.5.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.6.6.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.6.7.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.6.8.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.6.9.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.6.10.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.6.11.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.6.12.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.6.13.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/5.6.14.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/6.1.1.jpg">
<meta property="og:image" content="http://example.com/posts/498ab7d9/6.1.2.jpg">
<meta property="og:image" content="http://example.com/posts/498ab7d9/6.1.3.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/6.1.4.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/6.1.5.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/6.1.6.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/6.1.7.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.1.1.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.1.2.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.1.3.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.1.4.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.1.4.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.2.1.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.2.2.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.2.3.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.2.4.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.2.5.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.3.1.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.3.2.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.4.1.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.3.3.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.3.4.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.3.5.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.3.6.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.4.2.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.4.3.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.4.4.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.4.5.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.4.6.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.4.7.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.4.8.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.4.9.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.4.10.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.4.11.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.4.12.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.4.13.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.4.14.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.4.15.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.4.16.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.4.17.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.5.1.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.5.2.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.5.3.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.5.4.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.6.1.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.6.2.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.6.3.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.6.4.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.6.5.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.6.6.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.6.7.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.6.8.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.6.9.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.6.10.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.6.11.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.6.12.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.6.13.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.6.14.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.6.15.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.6.16.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.6.17.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.6.18.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.6.19.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.6.20.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.6.21.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.6.22.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.6.23.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.6.24.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.7.1.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.7.2.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.7.3.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.7.4.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.7.8.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.7.5.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.7.6.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.7.9.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.7.7.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.7.10.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.7.11.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.7.12.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.7.13.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.7.14.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.7.15.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.7.16.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.7.17.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/7.7.18.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.1.1.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.1.2.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.1.3.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.1.4.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.1.5.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.1.6.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.1.7.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.1.8.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.1.9.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.1.10.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.1.12.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.1.11.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.1.13.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.1.14.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.1.15.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.1.16.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.1.17.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.1.18.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.1.19.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.1.20.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.2.1.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.2.2.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.3.1.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.3.2.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.4.1.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.4.2.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.4.3.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.4.4.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.4.5.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.4.6.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.5.1.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.5.2.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.6.1.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.3.3.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.3.4.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.3.5.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.3.6.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.3.7.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.3.8.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.3.9.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.3.10.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.3.11.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.3.12.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.3.13.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.3.14.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.3.15.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.3.16.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.3.17.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.3.18.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.3.19.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.3.20.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.3.21.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.4.7.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.4.8.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.4.9.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.4.10.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.4.11.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.4.12.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.4.13.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.4.14.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.4.15.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.4.16.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.4.17.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.4.18.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.4.19.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.4.20.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.4.21.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.4.22.png">
<meta property="og:image" content="http://example.com/posts/498ab7d9/8.4.23.png">
<meta property="article:published_time" content="2022-04-29T02:53:43.610Z">
<meta property="article:modified_time" content="2022-06-17T05:49:00.185Z">
<meta property="article:author" content="v5le0n9">
<meta property="article:tag" content="机器学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/posts/498ab7d9/1.1.1.png">

<link rel="canonical" href="http://example.com/posts/498ab7d9.html">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>机器学习 | v5le0n9's garden</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style><link rel="alternate" href="/atom.xml" title="v5le0n9's garden" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">v5le0n9's garden</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">小凉的秘密基地</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <a href="https://github.com/v5le0n9" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://example.com/posts/498ab7d9.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.png">
      <meta itemprop="name" content="v5le0n9">
      <meta itemprop="description" content="v5le0n9's garden">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="v5le0n9's garden">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          机器学习
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2022-04-29 10:53:43" itemprop="dateCreated datePublished" datetime="2022-04-29T10:53:43+08:00">2022-04-29</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2022-06-17 13:49:00" itemprop="dateModified" datetime="2022-06-17T13:49:00+08:00">2022-06-17</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/" itemprop="url" rel="index"><span itemprop="name">基础知识</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>4.2k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="far fa-clock"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>4 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>做机器学习的实验做得我生无可恋，还是先补一下机器学习的几个算法的基本原理再说吧。</p>
<span id="more"></span>
<h1 id="1-统计学习概述"><a href="#1-统计学习概述" class="headerlink" title="1. 统计学习概述"></a>1. 统计学习概述</h1><h2 id="1-1-统计学习三要素"><a href="#1-1-统计学习三要素" class="headerlink" title="1.1. 统计学习三要素"></a>1.1. 统计学习三要素</h2><ul>
<li><p>模型：确定学习模型的集合。模型在未进行训练前，其可能的参数是多个甚至无穷的，故可能的模型也是多个甚至无穷的，这些模型构成的集合就是假设空间。</p>
<img src="/posts/498ab7d9/1.1.1.png" class="" title="假设空间">
<img src="/posts/498ab7d9/1.1.2.png" class="" title="假设空间">
</li>
<li><p>策略：确定模型选择的准则。即从假设空间中挑选出参数最优的模型的准则。模型的分类或预测结果与实际情况的误差（损失函数）越小，模型就越好。那么策略就是误差最小。</p>
<img src="/posts/498ab7d9/1.1.3.png" class="" title="策略">
<img src="/posts/498ab7d9/1.1.4.png" class="" title="损失函数">
<img src="/posts/498ab7d9/1.1.5.png" class="" title="策略">
</li>
<li><p>算法：实现求解最优模型的算法。即从假设空间中挑选模型的方法（等同于求解最佳的模型参数）。机器学习的参数求解通常都会转化为最优化问题，故学习算法通常是最优化算法，例如最速梯度下降法、牛顿法以及拟牛顿法等。</p>
</li>
</ul>
<p>以上是针对监督学习的三要素，下面是针对无监督学习的三要素：</p>
<img src="/posts/498ab7d9/1.1.6.png" class="" title="无监督学习的三要素">
<h2 id="1-2-监督学习"><a href="#1-2-监督学习" class="headerlink" title="1.2. 监督学习"></a>1.2. 监督学习</h2><p>监督学习：从标注数据中学习预测模型的机器学习问题，其本质是学习输入到输出的映射的统计规律。</p>
<p>输入空间：输入的所有可能取值的集合。</p>
<p>实例：每一个具体的输入，通常由特征向量表示。</p>
<p>特征空间：所有特征向量存在的空间。</p>
<p>输出空间：输出的所有可能取值的集合。</p>
<p>根据变量类型的不同，可分为回归问题、分类问题和标注问题。</p>
<p>回归问题：输入变量与输出变量均为连续变量的预测问题。</p>
<p>分类问题：输出变量为有限个离散变量的预测问题。</p>
<p>标注问题：输入变量与输出变量均为变量序列的预测问题。</p>
<img src="/posts/498ab7d9/1.3.1.png" class="" title="监督学习中的符号表示">
<img src="/posts/498ab7d9/1.3.2.png" class="" title="监督学习中的符号表示">
<h2 id="1-3-无监督学习"><a href="#1-3-无监督学习" class="headerlink" title="1.3. 无监督学习"></a>1.3. 无监督学习</h2><p>无监督学习：从无标注数据中学习预测模型的机器学习问题，其本质是学习数据中的统计规律或潜在结构。</p>
<img src="/posts/498ab7d9/1.4.1.png" class="" title="无监督学习中的符号表示">
<h2 id="1-4-模型评估与选择"><a href="#1-4-模型评估与选择" class="headerlink" title="1.4 模型评估与选择"></a>1.4 模型评估与选择</h2><p>训练误差：</p>
<img src="/posts/498ab7d9/1.5.1.png" class="" title="训练误差">
<p>测试误差：</p>
<img src="/posts/498ab7d9/1.5.2.png" class="" title="测试误差">
<p>误差率与准确率：</p>
<img src="/posts/498ab7d9/1.5.3.png" class="" title="误差率与准确率">
<p>多项式拟合案例：</p>
<img src="/posts/498ab7d9/1.5.4.png" class="" title="案例">
<img src="/posts/498ab7d9/1.5.5.png" class="" title="案例">
<img src="/posts/498ab7d9/1.5.6.png" class="" title="案例">
<p>过拟合：学习时选择的模型所包含的参数过多，以至于出现这一模型对已知数据预测得很好，但对未知数据预测得很差的现象。</p>
<img src="/posts/498ab7d9/1.5.7.png" class="" title="训练误差与测试误差">
<img src="/posts/498ab7d9/1.5.8.png" class="" title="训练误差与测试误差">
<p>欠拟合：模型拟合程度不高，数据距离拟合曲线较远，或指模型没有很好地捕捉到数据特征，不能够很好地拟合数据。</p>
<p>为了避免过拟合的问题出现，需要选择合适的模型。常用的模型选择方法：正则化和交叉验证。</p>
<h2 id="1-5-正则化和交叉验证"><a href="#1-5-正则化和交叉验证" class="headerlink" title="1.5 正则化和交叉验证"></a>1.5 正则化和交叉验证</h2><h3 id="1-5-1-正则化"><a href="#1-5-1-正则化" class="headerlink" title="1.5.1 正则化"></a>1.5.1 正则化</h3><p>正则化：实现结构风险最小化策略。</p>
<img src="/posts/498ab7d9/1.5.9.png" class="" title="正则化">
<img src="/posts/498ab7d9/1.5.10.png" class="" title="正则化项">
<p>奥卡姆剃刀原理：在模型选择时，选择所有可能模型中，能很好解释已知数据并且十分简单的模型。</p>
<h3 id="1-5-2-交叉验证"><a href="#1-5-2-交叉验证" class="headerlink" title="1.5.2 交叉验证"></a>1.5.2 交叉验证</h3><img src="/posts/498ab7d9/1.5.11.png" class="" title="数据充足的情况下">
<p>在数据不足的情况下：</p>
<ul>
<li>简单交叉验证：随即将数据分为两部分，即训练集和测试集。</li>
<li>S折交叉认证：随机将数据分为S个互不相交、大小相同的子集，其中以S-1个子集作为训练集，余下的子集作为测试集。</li>
<li>留一交叉验证：S折交叉验证的特殊情形，S=N，N为数据集的样本容量。(在数据极少的情况下使用)</li>
</ul>
<h2 id="1-6-泛化能力"><a href="#1-6-泛化能力" class="headerlink" title="1.6 泛化能力"></a>1.6 泛化能力</h2><img src="/posts/498ab7d9/1.6.1.png" class="" title="泛化误差">
<img src="/posts/498ab7d9/1.6.2.png" class="" title="泛化误差上界">
<img src="/posts/498ab7d9/1.6.3.png" class="" title="泛化误差上界">
<h2 id="1-7-生成模型与判别模型"><a href="#1-7-生成模型与判别模型" class="headerlink" title="1.7 生成模型与判别模型"></a>1.7 生成模型与判别模型</h2><h3 id="1-7-1-生成模型"><a href="#1-7-1-生成模型" class="headerlink" title="1.7.1 生成模型"></a>1.7.1 生成模型</h3><img src="/posts/498ab7d9/1.7.1.png" class="" title="生成模型">
<h3 id="1-7-2-判别模型"><a href="#1-7-2-判别模型" class="headerlink" title="1.7.2 判别模型"></a>1.7.2 判别模型</h3><img src="/posts/498ab7d9/1.7.2.png" class="" title="判别模型">
<h3 id="1-7-3-两者区别"><a href="#1-7-3-两者区别" class="headerlink" title="1.7.3 两者区别"></a>1.7.3 两者区别</h3><img src="/posts/498ab7d9/1.7.3.png" class="" title="生成模型VS判别模型">
<h2 id="1-8-监督学习应用"><a href="#1-8-监督学习应用" class="headerlink" title="1.8 监督学习应用"></a>1.8 监督学习应用</h2><h3 id="1-8-1-分类问题"><a href="#1-8-1-分类问题" class="headerlink" title="1.8.1 分类问题"></a>1.8.1 分类问题</h3><img src="/posts/498ab7d9/1.8.1.png" class="" title="二分类问题">
<img src="/posts/498ab7d9/1.8.2.png" class="" title="二分类问题">
<p>方法：感知机、K近邻法、朴素贝叶斯、决策树、Logistic回归。</p>
<p>应用：银行业务、网络安全、图像处理、手写识别、互联网搜索。</p>
<h3 id="1-8-2-标注问题"><a href="#1-8-2-标注问题" class="headerlink" title="1.8.2 标注问题"></a>1.8.2 标注问题</h3><img src="/posts/498ab7d9/1.8.3.png" class="" title="标注问题">
<p>方法：隐马尔可夫模型、条件随机场。</p>
<p>应用：信息抽取、自然语言处理。</p>
<h3 id="1-8-3-回归问题"><a href="#1-8-3-回归问题" class="headerlink" title="1.8.3 回归问题"></a>1.8.3 回归问题</h3><p>类型：</p>
<ul>
<li>按输入变量个数：一元回归、多元回归</li>
<li>按输入和输出变量之间的关系：线性回归、非线性回归</li>
</ul>
<p>损失函数：平方损失</p>
<p>应用：商务领域</p>
<h1 id="2-感知机"><a href="#2-感知机" class="headerlink" title="2. 感知机"></a>2. 感知机</h1><h2 id="2-1-感知机模型"><a href="#2-1-感知机模型" class="headerlink" title="2.1 感知机模型"></a>2.1 感知机模型</h2><img src="/posts/498ab7d9/2.1.1.png" class="" title="模型介绍">
<img src="/posts/498ab7d9/2.1.2.png" class="" title="模型介绍">
<p>在几何中，如果特征空间是n维的，则超平面是n-1维的子空间。比如特征空间是2维的，那么超平面就是一条直线，超平面用来分隔正类和负类。</p>
<img src="/posts/498ab7d9/2.1.3.png" class="" title="感知机模型的条件">
<img src="/posts/498ab7d9/2.1.4.png" class="" title="感知机学习策略">
<img src="/posts/498ab7d9/2.1.5.png" class="" title="感知机学习策略">
<h2 id="2-2-梯度下降法"><a href="#2-2-梯度下降法" class="headerlink" title="2.2 梯度下降法"></a>2.2 梯度下降法</h2><img src="/posts/498ab7d9/2.2.1.png" class="" title="梯度的概念">
<img src="/posts/498ab7d9/2.2.2.png" class="" title="梯度下降法的算法">
<p>例子：</p>
<img src="/posts/498ab7d9/2.2.3.png" class="" title="梯度下降法的例子">
<img src="/posts/498ab7d9/2.2.4.png" class="" title="梯度下降法的例子">
<p>梯度下降法的原理：</p>
<img src="/posts/498ab7d9/2.2.5.png" class="" title="梯度下降法的原理">
<img src="/posts/498ab7d9/2.2.6.png" class="" title="梯度下降法的原理">
<img src="/posts/498ab7d9/2.2.7.png" class="" title="梯度下降法的原理">
<h2 id="2-3-感知机的原始形式"><a href="#2-3-感知机的原始形式" class="headerlink" title="2.3 感知机的原始形式"></a>2.3 感知机的原始形式</h2><p>感知机采用监督学习中的二分类问题。原始形式用随机梯度下降法来更新w和b。</p>
<img src="/posts/498ab7d9/2.3.1.png" class="" title="感知机学习问题">
<img src="/posts/498ab7d9/2.3.2.png" class="" title="随机梯度下降法">
<p>原始形式的算法：</p>
<img src="/posts/498ab7d9/2.3.3.png" class="" title="原始形式的算法">
<p>例题分析：</p>
<img src="/posts/498ab7d9/2.3.4.png" class="" title="例题分析">
<img src="/posts/498ab7d9/2.3.5.png" class="" title="例题分析">
<img src="/posts/498ab7d9/2.3.6.png" class="" title="例题分析">
<img src="/posts/498ab7d9/2.3.7.png" class="" title="例题分析">
<img src="/posts/498ab7d9/2.3.8.png" class="" title="例题分析">
<img src="/posts/498ab7d9/2.3.9.png" class="" title="例题分析">
<h2 id="2-4-感知机的对偶形式"><a href="#2-4-感知机的对偶形式" class="headerlink" title="2.4 感知机的对偶形式"></a>2.4 感知机的对偶形式</h2><img src="/posts/498ab7d9/2.4.1.png" class="" title="原始形式">
<img src="/posts/498ab7d9/2.4.2.png" class="" title="原始形式">
<p>对偶形式的算法：</p>
<img src="/posts/498ab7d9/2.4.3.png" class="" title="对偶形式的算法">
<img src="/posts/498ab7d9/2.4.4.png" class="" title="对偶形式的算法">
<p>例题分析：</p>
<img src="/posts/498ab7d9/2.4.5.png" class="" title="例题分析">
<img src="/posts/498ab7d9/2.4.6.png" class="" title="例题分析">
<img src="/posts/498ab7d9/2.4.7.png" class="" title="例题分析">
<img src="/posts/498ab7d9/2.4.8.png" class="" title="例题分析">
<img src="/posts/498ab7d9/2.4.9.png" class="" title="例题分析">
<h2 id="2-5-算法的收敛性"><a href="#2-5-算法的收敛性" class="headerlink" title="2.5 算法的收敛性"></a>2.5 算法的收敛性</h2><img src="/posts/498ab7d9/2.5.1.png" class="" title="定理">
<img src="/posts/498ab7d9/2.5.2.png" class="" title="定理的证明">
<img src="/posts/498ab7d9/2.5.3.png" class="" title="定理的证明">
<img src="/posts/498ab7d9/2.5.4.png" class="" title="定理的证明">
<img src="/posts/498ab7d9/2.5.5.png" class="" title="定理的证明">
<img src="/posts/498ab7d9/2.5.6.png" class="" title="定理的证明">
<img src="/posts/498ab7d9/2.5.7.png" class="" title="算法的收敛性">
<h1 id="3-K近邻"><a href="#3-K近邻" class="headerlink" title="3. K近邻"></a>3. K近邻</h1><h2 id="3-1-K近邻相关概念"><a href="#3-1-K近邻相关概念" class="headerlink" title="3.1 K近邻相关概念"></a>3.1 K近邻相关概念</h2><img src="/posts/498ab7d9/3.1.1.png" class="" title="K近邻概念">
<img src="/posts/498ab7d9/3.1.2.png" class="" title="K近邻直观理解">
<p>K近邻算法：</p>
<img src="/posts/498ab7d9/3.1.3.png" class="" title="K近邻算法">
<p>误差率：</p>
<img src="/posts/498ab7d9/3.1.4.png" class="" title="误差率">
<img src="/posts/498ab7d9/3.1.5.png" class="" title="误差率">
<img src="/posts/498ab7d9/3.1.6.png" class="" title="误差率">
<img src="/posts/498ab7d9/3.1.7.png" class="" title="误差率">
<h2 id="3-2-K近邻三要素"><a href="#3-2-K近邻三要素" class="headerlink" title="3.2 K近邻三要素"></a>3.2 K近邻三要素</h2><h3 id="3-2-1-K近邻模型"><a href="#3-2-1-K近邻模型" class="headerlink" title="3.2.1 K近邻模型"></a>3.2.1 K近邻模型</h3><img src="/posts/498ab7d9/3.2.1.png" class="" title="K近邻模型">
<h3 id="3-2-2-距离度量"><a href="#3-2-2-距离度量" class="headerlink" title="3.2.2 距离度量"></a>3.2.2 距离度量</h3><img src="/posts/498ab7d9/3.2.2.png" class="" title="距离度量">
<img src="/posts/498ab7d9/3.2.3.png" class="" title="距离度量">
<img src="/posts/498ab7d9/3.2.4.png" class="" title="例子">
<img src="/posts/498ab7d9/3.2.5.png" class="" title="例子">
<img src="/posts/498ab7d9/3.2.6.png" class="" title="例子">
<h3 id="3-2-3-K值的选择"><a href="#3-2-3-K值的选择" class="headerlink" title="3.2.3 K值的选择"></a>3.2.3 K值的选择</h3><p>近似误差：可以理解为对现有训练集的训练误差。</p>
<p>估计误差：可以理解为对测试集的测试误差。</p>
<img src="/posts/498ab7d9/3.2.7.png" class="" title="K值的选择">
<h3 id="3-2-4-分类决策规则"><a href="#3-2-4-分类决策规则" class="headerlink" title="3.2.4 分类决策规则"></a>3.2.4 分类决策规则</h3><img src="/posts/498ab7d9/3.2.8.png" class="" title="分类决策规则">
<img src="/posts/498ab7d9/3.2.9.png" class="" title="分类决策规则">
<img src="/posts/498ab7d9/3.2.10.png" class="" title="分类决策规则">
<h2 id="3-3-构造KD树"><a href="#3-3-构造KD树" class="headerlink" title="3.3 构造KD树"></a>3.3 构造KD树</h2><img src="/posts/498ab7d9/3.3.1.png" class="" title="什么是KD树">
<img src="/posts/498ab7d9/3.3.2.png" class="" title="构造KD树">
<p>例子：</p>
<img src="/posts/498ab7d9/3.3.3.png" class="" title="构造KD树例子">
<img src="/posts/498ab7d9/3.3.4.png" class="" title="构造KD树例子">
<img src="/posts/498ab7d9/3.3.5.png" class="" title="构造KD树例子">
<img src="/posts/498ab7d9/3.3.6.png" class="" title="构造KD树例子">
<img src="/posts/498ab7d9/3.3.7.png" class="" title="构造KD树例子">
<img src="/posts/498ab7d9/3.3.8.png" class="" title="构造KD树例子">
<h2 id="3-4-搜索KD树"><a href="#3-4-搜索KD树" class="headerlink" title="3.4 搜索KD树"></a>3.4 搜索KD树</h2><p>最近邻搜索：</p>
<ul>
<li>寻找“当前最近点”：寻找最近邻的子结点作为目标点的“当前最近点”</li>
<li>回溯：以目标点和“当前最近点”的距离沿树根部进行回溯和迭代</li>
</ul>
<p>最近邻搜索算法：</p>
<img src="/posts/498ab7d9/3.4.1.png" class="" title="最近邻搜索算法">
<p>例子：</p>
<img src="/posts/498ab7d9/3.4.2.png" class="" title="最近邻搜索算法例子">
<img src="/posts/498ab7d9/3.4.3.png" class="" title="最近邻搜索算法例子">
<img src="/posts/498ab7d9/3.4.4.png" class="" title="最近邻搜索算法例子">
<h1 id="4-朴素贝叶斯法"><a href="#4-朴素贝叶斯法" class="headerlink" title="4. 朴素贝叶斯法"></a>4. 朴素贝叶斯法</h1><h2 id="4-1-贝叶斯定理"><a href="#4-1-贝叶斯定理" class="headerlink" title="4.1 贝叶斯定理"></a>4.1 贝叶斯定理</h2><p>条件概率：</p>
<script type="math/tex; mode=display">
P(X=x|Y=y_i)=\frac {P(X=x,Y=y_i)}{P(Y=y_i)}</script><p>全概率公式：</p>
<script type="math/tex; mode=display">
P(X=x)=\sum_{i=1}^nP(Y=y_i)P(X=x|Y=y_i)</script><p>贝叶斯公式：</p>
<script type="math/tex; mode=display">
P(Y=y_i|X=x)=\frac {P(X=x,Y=y_i)}{P(X=x)}=\frac{P(Y=y_i)P(X=x|Y=y_i)}{\sum_{i=1}^nP(Y=y_i)P(X=x|Y=y_i)}</script><img src="/posts/498ab7d9/4.1.3.png" class="" title="贝叶斯定理">
<img src="/posts/498ab7d9/4.1.4.png" class="" title="朴素贝叶斯">
<img src="/posts/498ab7d9/4.1.5.png" class="" title="朴素贝叶斯分类">
<h2 id="4-2-何为朴素"><a href="#4-2-何为朴素" class="headerlink" title="4.2 何为朴素"></a>4.2 何为朴素</h2><img src="/posts/498ab7d9/4.1.1.png" class="" title="朴素贝叶斯">
<img src="/posts/498ab7d9/4.1.2.png" class="" title="朴素贝叶斯">
<p>参数个数：</p>
<img src="/posts/498ab7d9/4.2.1.png" class="" title="朴素贝叶斯">
<p>“朴素”即为条件独立性假设，即特征之间相互独立。</p>
<img src="/posts/498ab7d9/4.2.2.png" class="" title="朴素贝叶斯">
<h2 id="4-3-后验概率最大化"><a href="#4-3-后验概率最大化" class="headerlink" title="4.3 后验概率最大化"></a>4.3 后验概率最大化</h2><p>将期望风险最小化转化为后验概率最大化的问题。</p>
<img src="/posts/498ab7d9/4.3.1.png" class="" title="后验概率最大化">
<h2 id="4-4-极大似然估计"><a href="#4-4-极大似然估计" class="headerlink" title="4.4 极大似然估计"></a>4.4 极大似然估计</h2><img src="/posts/498ab7d9/4.4.1.png" class="" title="先验概率与条件概率">
<p>极大似然估计原理：</p>
<img src="/posts/498ab7d9/4.4.2.png" class="" title="极大似然估计原理">
<p>极大似然估计实现：</p>
<img src="/posts/498ab7d9/4.4.3.png" class="" title="极大似然估计例子">
<img src="/posts/498ab7d9/4.4.4.png" class="" title="极大似然估计例子">
<img src="/posts/498ab7d9/4.4.5.png" class="" title="极大似然估计例子">
<img src="/posts/498ab7d9/4.4.6.png" class="" title="极大似然估计例子">
<img src="/posts/498ab7d9/4.4.7.png" class="" title="极大似然估计例子">
<img src="/posts/498ab7d9/4.4.8.png" class="" title="极大似然估计例子">
<h2 id="4-5-算法"><a href="#4-5-算法" class="headerlink" title="4.5 算法"></a>4.5 算法</h2><img src="/posts/498ab7d9/4.5.1.png" class="" title="朴素贝叶斯算法">
<img src="/posts/498ab7d9/4.5.2.png" class="" title="朴素贝叶斯例子">
<img src="/posts/498ab7d9/4.5.3.png" class="" title="朴素贝叶斯例子">
<h2 id="4-6-贝叶斯估计"><a href="#4-6-贝叶斯估计" class="headerlink" title="4.6 贝叶斯估计"></a>4.6 贝叶斯估计</h2><img src="/posts/498ab7d9/4.6.1.png" class="" title="贝叶斯估计">
<img src="/posts/498ab7d9/4.6.2.png" class="" title="贝叶斯估计">
<img src="/posts/498ab7d9/4.6.3.png" class="" title="贝叶斯估计">
<img src="/posts/498ab7d9/4.6.4.png" class="" title="贝叶斯估计">
<img src="/posts/498ab7d9/4.6.5.png" class="" title="贝叶斯估计">
<img src="/posts/498ab7d9/4.6.6.png" class="" title="贝叶斯估计">
<img src="/posts/498ab7d9/4.6.7.png" class="" title="贝叶斯估计">
<img src="/posts/498ab7d9/4.6.8.png" class="" title="正则化">
<img src="/posts/498ab7d9/4.6.9.png" class="" title="贝叶斯估计">
<h1 id="5-决策树"><a href="#5-决策树" class="headerlink" title="5. 决策树"></a>5. 决策树</h1><p>分类决策树模型是一种描述对实例进行分类的树形结构。</p>
<img src="/posts/498ab7d9/5.1.1.png" class="" title="决策树">
<p>决策树是通过一系列规则对数据进行分类的过程。</p>
<p>If-Then规则：</p>
<img src="/posts/498ab7d9/5.1.2.png" class="" title="If-Then规则">
<p>构建决策树：</p>
<ol>
<li>构建根节点</li>
<li>选择最优特征，以此分割训练数据集</li>
<li>若子集被基本正确分类，构建叶结点；否则，继续选择新的最优特征</li>
<li>重复2、3步，直到所有训练数据子集被正确分类</li>
</ol>
<h2 id="5-1-条件概率分布"><a href="#5-1-条件概率分布" class="headerlink" title="5.1 条件概率分布"></a>5.1 条件概率分布</h2><img src="/posts/498ab7d9/5.1.3.png" class="" title="条件概率分布">
<p>当单元c的条件概率满足<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.566ex" xmlns="http://www.w3.org/2000/svg" width="23.556ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 10411.7 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D443" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path></g><g data-mml-node="mo" transform="translate(751,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(1140,0)"><path data-c="1D44C" d="M66 637Q54 637 49 637T39 638T32 641T30 647T33 664T42 682Q44 683 56 683Q104 680 165 680Q288 680 306 683H316Q322 677 322 674T320 656Q316 643 310 637H298Q242 637 242 624Q242 619 292 477T343 333L346 336Q350 340 358 349T379 373T411 410T454 461Q546 568 561 587T577 618Q577 634 545 637Q528 637 528 647Q528 649 530 661Q533 676 535 679T549 683Q551 683 578 682T657 680Q684 680 713 681T746 682Q763 682 763 673Q763 669 760 657T755 643Q753 637 734 637Q662 632 617 587Q608 578 477 424L348 273L322 169Q295 62 295 57Q295 46 363 46Q379 46 384 45T390 35Q390 33 388 23Q384 6 382 4T366 1Q361 1 324 1T232 2Q170 2 138 2T102 1Q84 1 84 9Q84 14 87 24Q88 27 89 30T90 35T91 39T93 42T96 44T101 45T107 45T116 46T129 46Q168 47 180 50T198 63Q201 68 227 171L252 274L129 623Q128 624 127 625T125 627T122 629T118 631T113 633T105 634T96 635T83 636T66 637Z"></path></g><g data-mml-node="mo" transform="translate(2180.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mo" transform="translate(3236.6,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(4014.6,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(4514.6,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z"></path></g><g data-mml-node="mi" transform="translate(4792.6,0)"><path data-c="1D44B" d="M42 0H40Q26 0 26 11Q26 15 29 27Q33 41 36 43T55 46Q141 49 190 98Q200 108 306 224T411 342Q302 620 297 625Q288 636 234 637H206Q200 643 200 645T202 664Q206 677 212 683H226Q260 681 347 681Q380 681 408 681T453 682T473 682Q490 682 490 671Q490 670 488 658Q484 643 481 640T465 637Q434 634 411 620L488 426L541 485Q646 598 646 610Q646 628 622 635Q617 635 609 637Q594 637 594 648Q594 650 596 664Q600 677 606 683H618Q619 683 643 683T697 681T738 680Q828 680 837 683H845Q852 676 852 672Q850 647 840 637H824Q790 636 763 628T722 611T698 593L687 584Q687 585 592 480L505 384Q505 383 536 304T601 142T638 56Q648 47 699 46Q734 46 734 37Q734 35 732 23Q728 7 725 4T711 1Q708 1 678 1T589 2Q528 2 496 2T461 1Q444 1 444 10Q444 11 446 25Q448 35 450 39T455 44T464 46T480 47T506 54Q523 62 523 64Q522 64 476 181L429 299Q241 95 236 84Q232 76 232 72Q232 53 261 47Q262 47 267 47T273 46Q276 46 277 46T280 45T283 42T284 35Q284 26 282 19Q279 6 276 4T261 1Q258 1 243 1T201 2T142 2Q64 2 42 0Z"></path></g><g data-mml-node="mo" transform="translate(5922.3,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mi" transform="translate(6978.1,0)"><path data-c="1D450" d="M34 159Q34 268 120 355T306 442Q362 442 394 418T427 355Q427 326 408 306T360 285Q341 285 330 295T319 325T330 359T352 380T366 386H367Q367 388 361 392T340 400T306 404Q276 404 249 390Q228 381 206 359Q162 315 142 235T121 119Q121 73 147 50Q169 26 205 26H209Q321 26 394 111Q403 121 406 121Q410 121 419 112T429 98T420 83T391 55T346 25T282 0T202 -11Q127 -11 81 37T34 159Z"></path></g><g data-mml-node="mo" transform="translate(7411.1,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(8077.9,0)"><path data-c="3E" d="M84 520Q84 528 88 533T96 539L99 540Q106 540 253 471T544 334L687 265Q694 260 694 250T687 235Q685 233 395 96L107 -40H101Q83 -38 83 -20Q83 -19 83 -17Q82 -10 98 -1Q117 9 248 71Q326 108 378 132L626 250L378 368Q90 504 86 509Q84 513 84 520Z"></path></g><g data-mml-node="mn" transform="translate(9133.7,0)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z" transform="translate(500,0)"></path><path data-c="35" d="M164 157Q164 133 148 117T109 101H102Q148 22 224 22Q294 22 326 82Q345 115 345 210Q345 313 318 349Q292 382 260 382H254Q176 382 136 314Q132 307 129 306T114 304Q97 304 95 310Q93 314 93 485V614Q93 664 98 664Q100 666 102 666Q103 666 123 658T178 642T253 634Q324 634 389 662Q397 666 402 666Q410 666 410 648V635Q328 538 205 538Q174 538 149 544L139 546V374Q158 388 169 396T205 412T256 420Q337 420 393 355T449 201Q449 109 385 44T229 -22Q148 -22 99 32T50 154Q50 178 61 192T84 210T107 214Q132 214 148 197T164 157Z" transform="translate(778,0)"></path></g></g></g></svg></mjx-container>时，则认为该单元属于正类。</p>
<img src="/posts/498ab7d9/5.1.4.png" class="" title="条件概率分布">
<h2 id="5-2-决策树学习"><a href="#5-2-决策树学习" class="headerlink" title="5.2 决策树学习"></a>5.2 决策树学习</h2><img src="/posts/498ab7d9/5.2.1.png" class="" title="决策树学习">
<img src="/posts/498ab7d9/5.2.2.png" class="" title="决策树学习">
<h2 id="5-3-特征选择"><a href="#5-3-特征选择" class="headerlink" title="5.3 特征选择"></a>5.3 特征选择</h2><img src="/posts/498ab7d9/5.2.3.png" class="" title="特征选择">
<img src="/posts/498ab7d9/5.2.4.png" class="" title="特征选择">
<img src="/posts/498ab7d9/5.2.5.png" class="" title="特征选择">
<p>根据选择不同的特征作为根结点所得到的决策树不同。那么，如何进行特征选择呢？信息增益。</p>
<img src="/posts/498ab7d9/5.2.6.png" class="" title="熵">
<img src="/posts/498ab7d9/5.2.7.png" class="" title="信息增益">
<img src="/posts/498ab7d9/5.2.8.png" class="" title="信息增益">
<p>例子：</p>
<img src="/posts/498ab7d9/5.2.9.png" class="" title="经验熵">
<p>计算年龄特征的经验条件熵：</p>
<img src="/posts/498ab7d9/5.2.10.png" class="" title="条件经验熵">
<p>计算工作特征的经验条件熵：</p>
<img src="/posts/498ab7d9/5.2.11.png" class="" title="条件经验熵">
<p>计算有房子特征的经验条件熵：</p>
<img src="/posts/498ab7d9/5.2.12.png" class="" title="条件经验熵">
<p>计算信贷情况特征的经验条件熵：</p>
<img src="/posts/498ab7d9/5.2.13.png" class="" title="条件经验熵">
<p>信息增益：</p>
<img src="/posts/498ab7d9/5.2.14.png" class="" title="信息增益">
<p>哪个带来的信息增益最大选哪个特征作为根结点。</p>
<p>信息增益比：</p>
<img src="/posts/498ab7d9/5.2.17.png" class="" title="信息增益比">
<img src="/posts/498ab7d9/5.2.15.png" class="" title="信息增益比">
<p>哪个信息增益比最大选哪个特征作为根结点。</p>
<p>信息增益倾向于某个取值较多的特征，信息增益比倾向于某个取值较少的特征。</p>
<img src="/posts/498ab7d9/5.2.16.png" class="" title="信息增益与信息增益比">
<h2 id="5-4-决策树的生成"><a href="#5-4-决策树的生成" class="headerlink" title="5.4 决策树的生成"></a>5.4 决策树的生成</h2><h3 id="5-4-1-ID3算法"><a href="#5-4-1-ID3算法" class="headerlink" title="5.4.1 ID3算法"></a>5.4.1 ID3算法</h3><img src="/posts/498ab7d9/5.2.18.png" class="" title="ID3算法">
<p>例子：</p>
<img src="/posts/498ab7d9/5.2.20.png" class="" title="ID3算法例子">
<img src="/posts/498ab7d9/5.2.21.png" class="" title="ID3算法例子">
<img src="/posts/498ab7d9/5.2.22.png" class="" title="ID3算法例子">
<img src="/posts/498ab7d9/5.2.23.png" class="" title="ID3算法例子">
<img src="/posts/498ab7d9/5.2.24.png" class="" title="ID3算法例子">
<img src="/posts/498ab7d9/5.2.25.png" class="" title="ID3算法例子">
<img src="/posts/498ab7d9/5.2.26.png" class="" title="ID3算法例子">
<h3 id="5-4-2-C4-5算法"><a href="#5-4-2-C4-5算法" class="headerlink" title="5.4.2 C4.5算法"></a>5.4.2 C4.5算法</h3><img src="/posts/498ab7d9/5.2.19.png" class="" title="C4.5算法">
<h2 id="5-5-剪枝"><a href="#5-5-剪枝" class="headerlink" title="5.5 剪枝"></a>5.5 剪枝</h2><img src="/posts/498ab7d9/5.5.1.png" class="" title="剪枝">
<img src="/posts/498ab7d9/5.5.2.png" class="" title="剪枝">
<img src="/posts/498ab7d9/5.5.3.png" class="" title="剪枝">
<h3 id="5-5-1-预剪枝"><a href="#5-5-1-预剪枝" class="headerlink" title="5.5.1 预剪枝"></a>5.5.1 预剪枝</h3><p>预剪枝的几个方法：</p>
<ol>
<li>限定决策树的深度</li>
<li>设置一个阈值</li>
<li>设置某个指标，比较结点划分前后的泛化能力</li>
</ol>
<p>例子：</p>
<img src="/posts/498ab7d9/5.5.4.png" class="" title="预剪枝">
<p>深度为4，假设限定决策树的深度为2：</p>
<img src="/posts/498ab7d9/5.5.5.png" class="" title="预剪枝">
<img src="/posts/498ab7d9/5.5.6.png" class="" title="预剪枝">
<p>设定阈值为0.4：</p>
<img src="/posts/498ab7d9/5.5.7.png" class="" title="预剪枝">
<p>设置阈值过大，导致欠拟合现象。</p>
<p>设置某个指标，比较结点划分前后的泛化能力：</p>
<img src="/posts/498ab7d9/5.5.8.png" class="" title="预剪枝">
<p>此时的误差率为<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.816ex" xmlns="http://www.w3.org/2000/svg" width="1.795ex" height="2.79ex" role="img" focusable="false" viewBox="0 -872.7 793.6 1233.3"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mfrac"><g data-mml-node="mn" transform="translate(220,394) scale(0.707)"><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z"></path></g><g data-mml-node="mn" transform="translate(220,-345) scale(0.707)"><path data-c="37" d="M55 458Q56 460 72 567L88 674Q88 676 108 676H128V672Q128 662 143 655T195 646T364 644H485V605L417 512Q408 500 387 472T360 435T339 403T319 367T305 330T292 284T284 230T278 162T275 80Q275 66 275 52T274 28V19Q270 2 255 -10T221 -22Q210 -22 200 -19T179 0T168 40Q168 198 265 368Q285 400 349 489L395 552H302Q128 552 119 546Q113 543 108 522T98 479L95 458V455H55V458Z"></path></g><rect width="553.6" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container>。</p>
<img src="/posts/498ab7d9/5.5.9.png" class="" title="预剪枝">
<img src="/posts/498ab7d9/5.5.10.png" class="" title="预剪枝">
<p>经过计算，脐部特征的信息增益最大，将它作为根结点。判断测试集的泛化能力，误差率为<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.816ex" xmlns="http://www.w3.org/2000/svg" width="1.795ex" height="2.773ex" role="img" focusable="false" viewBox="0 -864.9 793.6 1225.5"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mfrac"><g data-mml-node="mn" transform="translate(220,394) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mn" transform="translate(220,-345) scale(0.707)"><path data-c="37" d="M55 458Q56 460 72 567L88 674Q88 676 108 676H128V672Q128 662 143 655T195 646T364 644H485V605L417 512Q408 500 387 472T360 435T339 403T319 367T305 330T292 284T284 230T278 162T275 80Q275 66 275 52T274 28V19Q270 2 255 -10T221 -22Q210 -22 200 -19T179 0T168 40Q168 198 265 368Q285 400 349 489L395 552H302Q128 552 119 546Q113 543 108 522T98 479L95 458V455H55V458Z"></path></g><rect width="553.6" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container>，比之前的误差率小，所以应该继续往下递归。</p>
<img src="/posts/498ab7d9/5.5.11.png" class="" title="预剪枝">
<p>在脐部的特征值为凹陷的训练集中，色泽的信息增益最大，将它作为子树。</p>
<img src="/posts/498ab7d9/5.5.12.png" class="" title="预剪枝">
<p>此时算出误差率为<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.816ex" xmlns="http://www.w3.org/2000/svg" width="1.795ex" height="2.771ex" role="img" focusable="false" viewBox="0 -864.2 793.6 1224.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mfrac"><g data-mml-node="mn" transform="translate(220,394) scale(0.707)"><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z"></path></g><g data-mml-node="mn" transform="translate(220,-345) scale(0.707)"><path data-c="37" d="M55 458Q56 460 72 567L88 674Q88 676 108 676H128V672Q128 662 143 655T195 646T364 644H485V605L417 512Q408 500 387 472T360 435T339 403T319 367T305 330T292 284T284 230T278 162T275 80Q275 66 275 52T274 28V19Q270 2 255 -10T221 -22Q210 -22 200 -19T179 0T168 40Q168 198 265 368Q285 400 349 489L395 552H302Q128 552 119 546Q113 543 108 522T98 479L95 458V455H55V458Z"></path></g><rect width="553.6" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container>，比<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.816ex" xmlns="http://www.w3.org/2000/svg" width="1.795ex" height="2.773ex" role="img" focusable="false" viewBox="0 -864.9 793.6 1225.5"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mfrac"><g data-mml-node="mn" transform="translate(220,394) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mn" transform="translate(220,-345) scale(0.707)"><path data-c="37" d="M55 458Q56 460 72 567L88 674Q88 676 108 676H128V672Q128 662 143 655T195 646T364 644H485V605L417 512Q408 500 387 472T360 435T339 403T319 367T305 330T292 284T284 230T278 162T275 80Q275 66 275 52T274 28V19Q270 2 255 -10T221 -22Q210 -22 200 -19T179 0T168 40Q168 198 265 368Q285 400 349 489L395 552H302Q128 552 119 546Q113 543 108 522T98 479L95 458V455H55V458Z"></path></g><rect width="553.6" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container>大，所以泛化能力下降，应该将它预剪枝。</p>
<img src="/posts/498ab7d9/5.5.13.png" class="" title="预剪枝">
<p>在脐部的特征值为稍凹的训练集中，根蒂的信息增益最大，将它作为子树。</p>
<img src="/posts/498ab7d9/5.5.14.png" class="" title="预剪枝">
<p>此时算出误差率为<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.816ex" xmlns="http://www.w3.org/2000/svg" width="1.795ex" height="2.773ex" role="img" focusable="false" viewBox="0 -864.9 793.6 1225.5"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mfrac"><g data-mml-node="mn" transform="translate(220,394) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mn" transform="translate(220,-345) scale(0.707)"><path data-c="37" d="M55 458Q56 460 72 567L88 674Q88 676 108 676H128V672Q128 662 143 655T195 646T364 644H485V605L417 512Q408 500 387 472T360 435T339 403T319 367T305 330T292 284T284 230T278 162T275 80Q275 66 275 52T274 28V19Q270 2 255 -10T221 -22Q210 -22 200 -19T179 0T168 40Q168 198 265 368Q285 400 349 489L395 552H302Q128 552 119 546Q113 543 108 522T98 479L95 458V455H55V458Z"></path></g><rect width="553.6" height="60" x="120" y="220"></rect></g></g></g></svg></mjx-container>，与之前误差率相同。根据奥卡姆剃刀原理，在相同效果下，越简单越好，所以也将它预剪枝。</p>
<img src="/posts/498ab7d9/5.5.15.png" class="" title="预剪枝">
<p>在脐部的特征值为平坦的训练集中，全是坏瓜，没有必要再次做划分。</p>
<h3 id="5-5-2-后剪枝"><a href="#5-5-2-后剪枝" class="headerlink" title="5.5.2 后剪枝"></a>5.5.2 后剪枝</h3><p>后剪枝的几个方法：</p>
<ol>
<li>降低错误剪枝(REP)</li>
<li>悲观错误剪枝(PEP)</li>
<li>最小误差剪枝(MEP)</li>
<li>基于错误的剪枝(EBP)</li>
<li>代价-复杂度剪枝(CCP)</li>
</ol>
<h4 id="5-5-2-1-降低错误剪枝-REP"><a href="#5-5-2-1-降低错误剪枝-REP" class="headerlink" title="5.5.2.1 降低错误剪枝(REP)"></a>5.5.2.1 降低错误剪枝(REP)</h4><img src="/posts/498ab7d9/5.5.16.png" class="" title="降低错误剪枝">
<img src="/posts/498ab7d9/5.5.17.png" class="" title="降低错误剪枝">
<img src="/posts/498ab7d9/5.5.18.png" class="" title="降低错误剪枝">
<p>如果不剪枝，误判个数为2：</p>
<img src="/posts/498ab7d9/5.5.19.png" class="" title="降低错误剪枝">
<p>剪枝后误判个数为1个，所以应该剪枝：</p>
<img src="/posts/498ab7d9/5.5.20.png" class="" title="降低错误剪枝">
<img src="/posts/498ab7d9/5.5.21.png" class="" title="降低错误剪枝">
<p>继续看能不能从3层变2层，色泽中的三个特征值有两个判断为好瓜，所以直接将稍蜷缩的判断为好瓜。</p>
<p>在剪枝前，误判个数为1个：</p>
<img src="/posts/498ab7d9/5.5.22.png" class="" title="降低错误剪枝">
<p>在剪枝后，误判个数为1个：</p>
<img src="/posts/498ab7d9/5.5.23.png" class="" title="降低错误剪枝">
<p>根据奥卡姆剃刀原理，选择剪枝。</p>
<p>继续看能不能从2层变1层，分别判断色泽特征和根蒂特征。最后可以得出是可以的：</p>
<img src="/posts/498ab7d9/5.5.24.png" class="" title="降低错误剪枝">
<h4 id="5-5-2-2-悲观错误剪枝-PEP"><a href="#5-5-2-2-悲观错误剪枝-PEP" class="headerlink" title="5.5.2.2 悲观错误剪枝(PEP)"></a>5.5.2.2 悲观错误剪枝(PEP)</h4><p>原理：根据剪枝前后的错误率来决定是否剪枝。和REP不同之处在于PEP只需要训练集即可，不需要验证集，并且PEP是自上而下剪枝的。</p>
<img src="/posts/498ab7d9/5.5.25.png" class="" title="悲观错误剪枝">
<p>例子：</p>
<img src="/posts/498ab7d9/5.3.1.png" class="" title="悲观错误剪枝">
<img src="/posts/498ab7d9/5.3.2.png" class="" title="悲观错误剪枝">
<img src="/posts/498ab7d9/5.3.2.png" class="" title="悲观错误剪枝">
<p>悲观错误剪枝的特点：</p>
<ul>
<li>不需要分离剪枝数据集，有利于实例较少的问题</li>
<li>误差使用了连续修正值，使得适用性更强</li>
<li>由于自上而下的剪枝策略，PEP效率更高</li>
<li>可能会修剪不应剪掉的枝条</li>
</ul>
<h4 id="5-5-2-3-最小误差剪枝-MEP"><a href="#5-5-2-3-最小误差剪枝-MEP" class="headerlink" title="5.5.2.3 最小误差剪枝(MEP)"></a>5.5.2.3 最小误差剪枝(MEP)</h4><p>原理：根据剪枝前后的最小分类错误概率来决定是否剪枝。自下而上剪枝，只需要训练集即可。</p>
<img src="/posts/498ab7d9/5.3.4.png" class="" title="最小误差剪枝">
<p>在实际操作中，m是选出来，而不是指定的。</p>
<img src="/posts/498ab7d9/5.3.5.png" class="" title="最小误差剪枝">
<p>例子：</p>
<img src="/posts/498ab7d9/5.3.6.png" class="" title="最小误差剪枝">
<h4 id="5-5-2-4-基于错误剪枝-EBP"><a href="#5-5-2-4-基于错误剪枝-EBP" class="headerlink" title="5.5.2.4 基于错误剪枝(EBP)"></a>5.5.2.4 基于错误剪枝(EBP)</h4><p>原理：根据剪枝前后的误判个数来决定是否剪枝。自下而上剪枝，只需要训练集即可。</p>
<img src="/posts/498ab7d9/5.3.7.png" class="" title="基于错误剪枝">
<img src="/posts/498ab7d9/5.3.8.png" class="" title="基于错误剪枝">
<img src="/posts/498ab7d9/5.3.9.png" class="" title="基于错误剪枝">
<p>例子：</p>
<img src="/posts/498ab7d9/5.3.10.png" class="" title="基于错误剪枝">
<h4 id="5-5-2-5-代价-复杂度剪枝-CCP"><a href="#5-5-2-5-代价-复杂度剪枝-CCP" class="headerlink" title="5.5.2.5 代价-复杂度剪枝(CCP)"></a>5.5.2.5 代价-复杂度剪枝(CCP)</h4><p>原理：根据剪枝前后的损失函数来决定是否剪枝。</p>
<img src="/posts/498ab7d9/5.3.11.png" class="" title="代价-复杂度剪枝">
<img src="/posts/498ab7d9/5.3.12.png" class="" title="代价-复杂度剪枝">
<h2 id="5-6-CART算法"><a href="#5-6-CART算法" class="headerlink" title="5.6 CART算法"></a>5.6 CART算法</h2><p>CART算法是二叉决策树。</p>
<h3 id="5-6-1-树的生成"><a href="#5-6-1-树的生成" class="headerlink" title="5.6.1 树的生成"></a>5.6.1 树的生成</h3><h4 id="5-6-1-1-分类树"><a href="#5-6-1-1-分类树" class="headerlink" title="5.6.1.1 分类树"></a>5.6.1.1 分类树</h4><img src="/posts/498ab7d9/5.6.1.png" class="" title="基尼指数">
<p>将甜度特征作为分类：</p>
<img src="/posts/498ab7d9/5.6.2.png" class="" title="基尼指数例子">
<p>将硬度特征作为分类：</p>
<img src="/posts/498ab7d9/5.6.3.png" class="" title="基尼指数例子">
<p>0.48 &gt; 0.17，甜度特征更有利于桃子的分类，因为它的基尼指数更小，分得更彻底。</p>
<p><strong>CART分类决策树算法</strong>：</p>
<img src="/posts/498ab7d9/5.6.4.png" class="" title="CART算法">
<p>例子：</p>
<img src="/posts/498ab7d9/5.6.5.png" class="" title="CART算法例子">
<img src="/posts/498ab7d9/5.6.6.png" class="" title="CART算法例子">
<img src="/posts/498ab7d9/5.6.7.png" class="" title="CART算法例子">
<img src="/posts/498ab7d9/5.6.8.png" class="" title="CART算法例子">
<p>对比这四个特征的基尼指数，发现第三个特征的基尼指数最小，所以用它作为根结点来进行划分。再来看其它三个特征，重复上述步骤。</p>
<img src="/posts/498ab7d9/5.6.9.png" class="" title="CART算法例子">
<h4 id="5-6-1-2-回归树"><a href="#5-6-1-2-回归树" class="headerlink" title="5.6.1.2 回归树"></a>5.6.1.2 回归树</h4><img src="/posts/498ab7d9/5.6.10.png" class="" title="回归树模型">
<img src="/posts/498ab7d9/5.6.11.png" class="" title="回归树模型">
<p><strong>回归树算法</strong>：</p>
<img src="/posts/498ab7d9/5.6.12.png" class="" title="回归树算法步骤">
<h3 id="5-6-2-树的剪枝"><a href="#5-6-2-树的剪枝" class="headerlink" title="5.6.2 树的剪枝"></a>5.6.2 树的剪枝</h3><img src="/posts/498ab7d9/5.6.13.png" class="" title="回归树树的剪枝">
<img src="/posts/498ab7d9/5.6.14.png" class="" title="回归树树的剪枝">
<h1 id="6-逻辑回归"><a href="#6-逻辑回归" class="headerlink" title="6. 逻辑回归"></a>6. 逻辑回归</h1><img src="/posts/498ab7d9/6.1.1.jpg" class="" title="逻辑回归">
<img src="/posts/498ab7d9/6.1.2.jpg" class="" title="逻辑回归">
<img src="/posts/498ab7d9/6.1.3.png" class="" title="二项逻辑回归模型">
<img src="/posts/498ab7d9/6.1.4.png" class="" title="二项逻辑回归模型">
<img src="/posts/498ab7d9/6.1.5.png" class="" title="二项逻辑回归模型">
<img src="/posts/498ab7d9/6.1.6.png" class="" title="最大似然估计">
<img src="/posts/498ab7d9/6.1.7.png" class="" title="最大似然估计">
<h1 id="7-最大熵模型"><a href="#7-最大熵模型" class="headerlink" title="7. 最大熵模型"></a>7. 最大熵模型</h1><h2 id="7-1-最大熵原理"><a href="#7-1-最大熵原理" class="headerlink" title="7.1 最大熵原理"></a>7.1 最大熵原理</h2><h3 id="7-1-1-离散分布"><a href="#7-1-1-离散分布" class="headerlink" title="7.1.1 离散分布"></a>7.1.1 离散分布</h3><img src="/posts/498ab7d9/7.1.1.png" class="" title="离散分布">
<img src="/posts/498ab7d9/7.1.2.png" class="" title="离散分布">
<img src="/posts/498ab7d9/7.1.3.png" class="" title="离散分布">
<img src="/posts/498ab7d9/7.1.4.png" class="" title="离散分布">
<h3 id="7-1-2-连续分布"><a href="#7-1-2-连续分布" class="headerlink" title="7.1.2 连续分布"></a>7.1.2 连续分布</h3><p>在连续变量的情况下，最大熵是正态分布。证明如下：</p>
<img src="/posts/498ab7d9/7.1.4.png" class="" title="连续分布">
<h2 id="7-2-最大熵模型"><a href="#7-2-最大熵模型" class="headerlink" title="7.2 最大熵模型"></a>7.2 最大熵模型</h2><img src="/posts/498ab7d9/7.2.1.png" class="" title="最大熵模型">
<img src="/posts/498ab7d9/7.2.2.png" class="" title="特征函数">
<img src="/posts/498ab7d9/7.2.3.png" class="" title="最大熵模型的例子">
<p>经验分布相当于上帝视角的估计值。</p>
<img src="/posts/498ab7d9/7.2.4.png" class="" title="经验分布">
<img src="/posts/498ab7d9/7.2.5.png" class="" title="条件熵">
<h2 id="7-3-寻找最大条件熵"><a href="#7-3-寻找最大条件熵" class="headerlink" title="7.3 寻找最大条件熵"></a>7.3 寻找最大条件熵</h2><p>拉格朗日乘子法：</p>
<img src="/posts/498ab7d9/7.3.1.png" class="" title="寻找最大条件熵">
<img src="/posts/498ab7d9/7.3.2.png" class="" title="寻找最大条件熵">
<p>原始问题：</p>
<img src="/posts/498ab7d9/7.4.1.png" class="" title="原始问题">
<p>对偶问题：</p>
<img src="/posts/498ab7d9/7.3.3.png" class="" title="对偶问题">
<p>原始问题和对偶问题的最优解：</p>
<img src="/posts/498ab7d9/7.3.4.png" class="" title="原始问题和对偶问题">
<img src="/posts/498ab7d9/7.3.5.png" class="" title="原始问题和对偶问题">
<img src="/posts/498ab7d9/7.3.6.png" class="" title="原始问题和对偶问题">
<h2 id="7-4-最大熵模型的学习"><a href="#7-4-最大熵模型的学习" class="headerlink" title="7.4 最大熵模型的学习"></a>7.4 最大熵模型的学习</h2><img src="/posts/498ab7d9/7.4.2.png" class="" title="最大熵模型的学习">
<img src="/posts/498ab7d9/7.4.3.png" class="" title="最大熵模型的学习">
<img src="/posts/498ab7d9/7.4.4.png" class="" title="最大熵模型的学习">
<p>原始问题和对偶问题的最优解相同吗？</p>
<img src="/posts/498ab7d9/7.4.5.png" class="" title="原始问题和对偶问题">
<img src="/posts/498ab7d9/7.4.6.png" class="" title="原始问题和对偶问题">
<p>证明熵函数H(P)是严格凹函数(上凸函数)：</p>
<img src="/posts/498ab7d9/7.4.7.png" class="" title="证明">
<img src="/posts/498ab7d9/7.4.8.png" class="" title="证明">
<p>利用对偶问题解决原始问题：</p>
<img src="/posts/498ab7d9/7.4.9.png" class="" title="对偶问题解决原始问题">
<img src="/posts/498ab7d9/7.4.10.png" class="" title="对偶问题解决原始问题">
<img src="/posts/498ab7d9/7.4.11.png" class="" title="对偶问题解决原始问题">
<img src="/posts/498ab7d9/7.4.12.png" class="" title="对偶问题解决原始问题">
<img src="/posts/498ab7d9/7.4.13.png" class="" title="对偶问题解决原始问题">
<p>例子：</p>
<img src="/posts/498ab7d9/7.4.14.png" class="" title="例子">
<img src="/posts/498ab7d9/7.4.15.png" class="" title="例子">
<img src="/posts/498ab7d9/7.4.16.png" class="" title="例子">
<img src="/posts/498ab7d9/7.4.17.png" class="" title="例子">
<h2 id="7-5-极大似然估计"><a href="#7-5-极大似然估计" class="headerlink" title="7.5 极大似然估计"></a>7.5 极大似然估计</h2><img src="/posts/498ab7d9/7.5.1.png" class="" title="极大似然估计">
<img src="/posts/498ab7d9/7.5.2.png" class="" title="极大似然估计">
<img src="/posts/498ab7d9/7.5.3.png" class="" title="极大似然估计">
<img src="/posts/498ab7d9/7.5.4.png" class="" title="极大似然估计">
<h2 id="7-6-优化算法"><a href="#7-6-优化算法" class="headerlink" title="7.6 优化算法"></a>7.6 优化算法</h2><h3 id="7-6-1-最速梯度下降法"><a href="#7-6-1-最速梯度下降法" class="headerlink" title="7.6.1 最速梯度下降法"></a>7.6.1 最速梯度下降法</h3><img src="/posts/498ab7d9/7.6.1.png" class="" title="最速梯度下降法">
<img src="/posts/498ab7d9/7.6.2.png" class="" title="最速梯度下降法">
<img src="/posts/498ab7d9/7.6.3.png" class="" title="最速梯度下降法">
<img src="/posts/498ab7d9/7.6.4.png" class="" title="最速梯度下降法">
<img src="/posts/498ab7d9/7.6.5.png" class="" title="最速梯度下降法">
<h3 id="7-6-2-牛顿法"><a href="#7-6-2-牛顿法" class="headerlink" title="7.6.2 牛顿法"></a>7.6.2 牛顿法</h3><h4 id="7-6-2-1-求零点"><a href="#7-6-2-1-求零点" class="headerlink" title="7.6.2.1 求零点"></a>7.6.2.1 求零点</h4><img src="/posts/498ab7d9/7.6.6.png" class="" title="牛顿法求零点">
<img src="/posts/498ab7d9/7.6.7.png" class="" title="牛顿法求零点">
<img src="/posts/498ab7d9/7.6.8.png" class="" title="牛顿法求零点">
<img src="/posts/498ab7d9/7.6.9.png" class="" title="牛顿法求零点">
<img src="/posts/498ab7d9/7.6.10.png" class="" title="牛顿法求零点">
<img src="/posts/498ab7d9/7.6.11.png" class="" title="牛顿法求零点">
<img src="/posts/498ab7d9/7.6.12.png" class="" title="牛顿法求零点">
<img src="/posts/498ab7d9/7.6.13.png" class="" title="牛顿法求零点">
<img src="/posts/498ab7d9/7.6.14.png" class="" title="牛顿法求零点">
<img src="/posts/498ab7d9/7.6.15.png" class="" title="牛顿法求零点">
<img src="/posts/498ab7d9/7.6.16.png" class="" title="牛顿法求零点">
<h4 id="7-6-2-1-求极小值"><a href="#7-6-2-1-求极小值" class="headerlink" title="7.6.2.1 求极小值"></a>7.6.2.1 求极小值</h4><img src="/posts/498ab7d9/7.6.17.png" class="" title="牛顿法求极小值">
<img src="/posts/498ab7d9/7.6.18.png" class="" title="牛顿法求极小值">
<img src="/posts/498ab7d9/7.6.19.png" class="" title="牛顿法求极小值">
<p>例子：</p>
<img src="/posts/498ab7d9/7.6.20.png" class="" title="牛顿法求极小值例子">
<p>推广到求多元的情况下：</p>
<img src="/posts/498ab7d9/7.6.21.png" class="" title="牛顿法求极小值例子">
<img src="/posts/498ab7d9/7.6.22.png" class="" title="牛顿法求极小值例子">
<img src="/posts/498ab7d9/7.6.23.png" class="" title="牛顿法求极小值例子">
<img src="/posts/498ab7d9/7.6.24.png" class="" title="牛顿法求极小值例子">
<h3 id="7-6-3-拟牛顿法"><a href="#7-6-3-拟牛顿法" class="headerlink" title="7.6.3 拟牛顿法"></a>7.6.3 拟牛顿法</h3><h4 id="7-6-3-1-条件"><a href="#7-6-3-1-条件" class="headerlink" title="7.6.3.1 条件"></a>7.6.3.1 条件</h4><img src="/posts/498ab7d9/7.7.1.png" class="" title="拟牛顿法条件">
<h4 id="7-6-3-2-一维搜索"><a href="#7-6-3-2-一维搜索" class="headerlink" title="7.6.3.2 一维搜索"></a>7.6.3.2 一维搜索</h4><img src="/posts/498ab7d9/7.7.2.png" class="" title="一维搜索">
<h4 id="7-6-3-3-DFP算法"><a href="#7-6-3-3-DFP算法" class="headerlink" title="7.6.3.3 DFP算法"></a>7.6.3.3 DFP算法</h4><img src="/posts/498ab7d9/7.7.3.png" class="" title="DFP算法">
<img src="/posts/498ab7d9/7.7.4.png" class="" title="DFP算法">
<p>DFP应用于最大熵模型：</p>
<img src="/posts/498ab7d9/7.7.8.png" class="" title="DFP算法应用于最大熵模型">
<h4 id="7-6-3-4-BFGS算法"><a href="#7-6-3-4-BFGS算法" class="headerlink" title="7.6.3.4 BFGS算法"></a>7.6.3.4 BFGS算法</h4><img src="/posts/498ab7d9/7.7.5.png" class="" title="BFGS算法">
<img src="/posts/498ab7d9/7.7.6.png" class="" title="BFGS算法">
<p>BFGS应用于最大熵模型：</p>
<img src="/posts/498ab7d9/7.7.9.png" class="" title="BFGS应用于最大熵模型">
<h4 id="7-6-3-5-Broyden算法"><a href="#7-6-3-5-Broyden算法" class="headerlink" title="7.6.3.5 Broyden算法"></a>7.6.3.5 Broyden算法</h4><img src="/posts/498ab7d9/7.7.7.png" class="" title="Broyden算法">
<h3 id="7-6-4-迭代尺度法"><a href="#7-6-4-迭代尺度法" class="headerlink" title="7.6.4 迭代尺度法"></a>7.6.4 迭代尺度法</h3><img src="/posts/498ab7d9/7.7.10.png" class="" title="迭代尺度法">
<img src="/posts/498ab7d9/7.7.11.png" class="" title="迭代尺度法">
<img src="/posts/498ab7d9/7.7.12.png" class="" title="迭代尺度法">
<img src="/posts/498ab7d9/7.7.13.png" class="" title="迭代尺度法">
<img src="/posts/498ab7d9/7.7.14.png" class="" title="迭代尺度法">
<img src="/posts/498ab7d9/7.7.15.png" class="" title="迭代尺度法">
<img src="/posts/498ab7d9/7.7.16.png" class="" title="迭代尺度法">
<img src="/posts/498ab7d9/7.7.17.png" class="" title="迭代尺度法">
<img src="/posts/498ab7d9/7.7.18.png" class="" title="迭代尺度法">
<h1 id="8-支持向量机"><a href="#8-支持向量机" class="headerlink" title="8. 支持向量机"></a>8. 支持向量机</h1><img src="/posts/498ab7d9/8.1.1.png" class="" title="分类决策">
<img src="/posts/498ab7d9/8.1.2.png" class="" title="逻辑回归与感知机">
<img src="/posts/498ab7d9/8.1.3.png" class="" title="支持向量机">
<h2 id="8-1-线性可分支持向量机"><a href="#8-1-线性可分支持向量机" class="headerlink" title="8.1 线性可分支持向量机"></a>8.1 线性可分支持向量机</h2><h3 id="8-1-1-原始算法"><a href="#8-1-1-原始算法" class="headerlink" title="8.1.1 原始算法"></a>8.1.1 原始算法</h3><img src="/posts/498ab7d9/8.1.4.png" class="" title="几何间隔">
<img src="/posts/498ab7d9/8.1.5.png" class="" title="几何间隔">
<img src="/posts/498ab7d9/8.1.6.png" class="" title="函数间隔">
<img src="/posts/498ab7d9/8.1.7.png" class="" title="函数间隔">
<img src="/posts/498ab7d9/8.1.8.png" class="" title="函数间隔">
<img src="/posts/498ab7d9/8.1.9.png" class="" title="凸优化问题">
<img src="/posts/498ab7d9/8.1.10.png" class="" title="凸优化问题">
<img src="/posts/498ab7d9/8.1.12.png" class="" title="证明唯一性"> 
<img src="/posts/498ab7d9/8.1.11.png" class="" title="证明唯一性"> 
<img src="/posts/498ab7d9/8.1.13.png" class="" title="最大间隔算法"> 
<img src="/posts/498ab7d9/8.1.14.png" class="" title="最大间隔算法的例子"> 
<h3 id="8-1-2-对偶算法"><a href="#8-1-2-对偶算法" class="headerlink" title="8.1.2 对偶算法"></a>8.1.2 对偶算法</h3><img src="/posts/498ab7d9/8.1.15.png" class="" title="对偶问题"> 
<img src="/posts/498ab7d9/8.1.16.png" class="" title="对偶问题"> 
<img src="/posts/498ab7d9/8.1.17.png" class="" title="对偶问题"> 
<img src="/posts/498ab7d9/8.1.18.png" class="" title="对偶问题"> 
<img src="/posts/498ab7d9/8.1.19.png" class="" title="对偶算法"> 
<img src="/posts/498ab7d9/8.1.20.png" class="" title="对偶算法的例子"> 
<img src="/posts/498ab7d9/8.2.1.png" class="" title="对偶算法的例子"> 
<img src="/posts/498ab7d9/8.2.2.png" class="" title="对偶算法的例子"> 
<h2 id="8-2-线性不可分支持向量机"><a href="#8-2-线性不可分支持向量机" class="headerlink" title="8.2 线性不可分支持向量机"></a>8.2 线性不可分支持向量机</h2><h3 id="8-2-1-原始算法"><a href="#8-2-1-原始算法" class="headerlink" title="8.2.1 原始算法"></a>8.2.1 原始算法</h3><img src="/posts/498ab7d9/8.3.1.png" class="" title="线性支持向量机的原始算法"> 
<img src="/posts/498ab7d9/8.3.2.png" class="" title="线性支持向量机的原始算法"> 
<h3 id="8-2-2-对偶算法"><a href="#8-2-2-对偶算法" class="headerlink" title="8.2.2 对偶算法"></a>8.2.2 对偶算法</h3><img src="/posts/498ab7d9/8.4.1.png" class="" title="线性支持向量机的对偶算法"> 
<img src="/posts/498ab7d9/8.4.2.png" class="" title="线性支持向量机的对偶算法"> 
<img src="/posts/498ab7d9/8.4.3.png" class="" title="线性支持向量机的对偶算法"> 
<img src="/posts/498ab7d9/8.4.4.png" class="" title="线性支持向量机的对偶算法"> 
<img src="/posts/498ab7d9/8.4.5.png" class="" title="线性支持向量机"> 
<img src="/posts/498ab7d9/8.4.6.png" class="" title="线性支持向量机"> 
<h3 id="8-2-3-合页损失"><a href="#8-2-3-合页损失" class="headerlink" title="8.2.3 合页损失"></a>8.2.3 合页损失</h3><img src="/posts/498ab7d9/8.5.1.png" class="" title="合页损失"> 
<img src="/posts/498ab7d9/8.5.2.png" class="" title="合页损失"> 
<h2 id="8-3-非线性支持向量机"><a href="#8-3-非线性支持向量机" class="headerlink" title="8.3 非线性支持向量机"></a>8.3 非线性支持向量机</h2><img src="/posts/498ab7d9/8.6.1.png" class="" title="非线性支持向量机"> 
<h3 id="8-3-1-核函数"><a href="#8-3-1-核函数" class="headerlink" title="8.3.1 核函数"></a>8.3.1 核函数</h3><img src="/posts/498ab7d9/8.3.3.png" class="" title="核函数"> 
<img src="/posts/498ab7d9/8.3.4.png" class="" title="核函数">
<img src="/posts/498ab7d9/8.3.5.png" class="" title="核函数">
<img src="/posts/498ab7d9/8.3.6.png" class="" title="核函数">
<img src="/posts/498ab7d9/8.3.7.png" class="" title="核函数">
<img src="/posts/498ab7d9/8.3.8.png" class="" title="核函数">
<img src="/posts/498ab7d9/8.3.9.png" class="" title="核函数">
<img src="/posts/498ab7d9/8.3.10.png" class="" title="核函数">
<img src="/posts/498ab7d9/8.3.11.png" class="" title="核函数">
<img src="/posts/498ab7d9/8.3.12.png" class="" title="核函数">
<img src="/posts/498ab7d9/8.3.13.png" class="" title="核函数">
<img src="/posts/498ab7d9/8.3.14.png" class="" title="核函数">
<img src="/posts/498ab7d9/8.3.15.png" class="" title="核函数">
<img src="/posts/498ab7d9/8.3.16.png" class="" title="核函数">
<img src="/posts/498ab7d9/8.3.17.png" class="" title="核函数">
<h3 id="8-3-2-定义在欧氏空间的正定核函数"><a href="#8-3-2-定义在欧氏空间的正定核函数" class="headerlink" title="8.3.2 定义在欧氏空间的正定核函数"></a>8.3.2 定义在欧氏空间的正定核函数</h3><img src="/posts/498ab7d9/8.3.18.png" class="" title="欧氏空间核函数">
<h3 id="8-3-3-定义在离散数据集合的正定核函数"><a href="#8-3-3-定义在离散数据集合的正定核函数" class="headerlink" title="8.3.3 定义在离散数据集合的正定核函数"></a>8.3.3 定义在离散数据集合的正定核函数</h3><img src="/posts/498ab7d9/8.3.19.png" class="" title="离散集合核函数">
<img src="/posts/498ab7d9/8.3.20.png" class="" title="字符串核函数">
<img src="/posts/498ab7d9/8.3.21.png" class="" title="字符串核函数">
<h3 id="8-3-4-非支持向量机的算法"><a href="#8-3-4-非支持向量机的算法" class="headerlink" title="8.3.4 非支持向量机的算法"></a>8.3.4 非支持向量机的算法</h3><img src="/posts/498ab7d9/8.4.7.png" class="" title="支持向量机和非支持向量机的区别">
<h4 id="8-3-4-1-坐标下降法"><a href="#8-3-4-1-坐标下降法" class="headerlink" title="8.3.4.1 坐标下降法"></a>8.3.4.1 坐标下降法</h4><img src="/posts/498ab7d9/8.4.8.png" class="" title="坐标下降法">
<img src="/posts/498ab7d9/8.4.9.png" class="" title="坐标下降法">
<h4 id="8-3-4-2-SMO-序列最小最优-算法"><a href="#8-3-4-2-SMO-序列最小最优-算法" class="headerlink" title="8.3.4.2 SMO(序列最小最优)算法"></a>8.3.4.2 SMO(序列最小最优)算法</h4><img src="/posts/498ab7d9/8.4.10.png" class="" title="SMO算法">
<img src="/posts/498ab7d9/8.4.11.png" class="" title="SMO算法">
<img src="/posts/498ab7d9/8.4.12.png" class="" title="SMO算法">
<img src="/posts/498ab7d9/8.4.13.png" class="" title="SMO算法">
<img src="/posts/498ab7d9/8.4.14.png" class="" title="SMO算法">
<img src="/posts/498ab7d9/8.4.15.png" class="" title="SMO算法">
<img src="/posts/498ab7d9/8.4.16.png" class="" title="SMO算法">
<img src="/posts/498ab7d9/8.4.17.png" class="" title="SMO算法">
<img src="/posts/498ab7d9/8.4.18.png" class="" title="SMO算法">
<img src="/posts/498ab7d9/8.4.19.png" class="" title="SMO算法">
<img src="/posts/498ab7d9/8.4.20.png" class="" title="SMO算法">
<img src="/posts/498ab7d9/8.4.21.png" class="" title="SMO算法">
<img src="/posts/498ab7d9/8.4.22.png" class="" title="SMO算法">
<img src="/posts/498ab7d9/8.4.23.png" class="" title="SMO算法">
    </div>

    
    
    
        <div class="reward-container">
  <div></div>
  <button onclick="var qr = document.getElementById('qr'); qr.style.display = (qr.style.display === 'none') ? 'block' : 'none';">
    打赏
  </button>
  <div id="qr" style="display: none;">
      
      <div style="display: inline-block;">
        <img src="/images/wechatpay.jpg" alt="v5le0n9 微信支付">
        <p>微信支付</p>
      </div>
      
      <div style="display: inline-block;">
        <img src="/images/alipay.jpg" alt="v5le0n9 支付宝">
        <p>支付宝</p>
      </div>

  </div>
</div>


      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/" rel="tag"><i class="fa fa-tag"></i> 机器学习</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/posts/5850d757.html" rel="prev" title="2022DASCTF Apr X FATE 防疫挑战赛">
      <i class="fa fa-chevron-left"></i> 2022DASCTF Apr X FATE 防疫挑战赛
    </a></div>
      <div class="post-nav-item">
    <a href="/posts/7b52fae7.html" rel="next" title="奇安信安全方向笔试题">
      奇安信安全方向笔试题 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="gitalk-container"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#1-%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%BF%B0"><span class="nav-text">1. 统计学习概述</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-1-%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E4%B8%89%E8%A6%81%E7%B4%A0"><span class="nav-text">1.1. 统计学习三要素</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-2-%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0"><span class="nav-text">1.2. 监督学习</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-3-%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0"><span class="nav-text">1.3. 无监督学习</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-4-%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E9%80%89%E6%8B%A9"><span class="nav-text">1.4 模型评估与选择</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-5-%E6%AD%A3%E5%88%99%E5%8C%96%E5%92%8C%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81"><span class="nav-text">1.5 正则化和交叉验证</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-5-1-%E6%AD%A3%E5%88%99%E5%8C%96"><span class="nav-text">1.5.1 正则化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-5-2-%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81"><span class="nav-text">1.5.2 交叉验证</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-6-%E6%B3%9B%E5%8C%96%E8%83%BD%E5%8A%9B"><span class="nav-text">1.6 泛化能力</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-7-%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B%E4%B8%8E%E5%88%A4%E5%88%AB%E6%A8%A1%E5%9E%8B"><span class="nav-text">1.7 生成模型与判别模型</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-7-1-%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B"><span class="nav-text">1.7.1 生成模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-7-2-%E5%88%A4%E5%88%AB%E6%A8%A1%E5%9E%8B"><span class="nav-text">1.7.2 判别模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-7-3-%E4%B8%A4%E8%80%85%E5%8C%BA%E5%88%AB"><span class="nav-text">1.7.3 两者区别</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-8-%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E5%BA%94%E7%94%A8"><span class="nav-text">1.8 监督学习应用</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-8-1-%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98"><span class="nav-text">1.8.1 分类问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-8-2-%E6%A0%87%E6%B3%A8%E9%97%AE%E9%A2%98"><span class="nav-text">1.8.2 标注问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-8-3-%E5%9B%9E%E5%BD%92%E9%97%AE%E9%A2%98"><span class="nav-text">1.8.3 回归问题</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-%E6%84%9F%E7%9F%A5%E6%9C%BA"><span class="nav-text">2. 感知机</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1-%E6%84%9F%E7%9F%A5%E6%9C%BA%E6%A8%A1%E5%9E%8B"><span class="nav-text">2.1 感知机模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-2-%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95"><span class="nav-text">2.2 梯度下降法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-3-%E6%84%9F%E7%9F%A5%E6%9C%BA%E7%9A%84%E5%8E%9F%E5%A7%8B%E5%BD%A2%E5%BC%8F"><span class="nav-text">2.3 感知机的原始形式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-4-%E6%84%9F%E7%9F%A5%E6%9C%BA%E7%9A%84%E5%AF%B9%E5%81%B6%E5%BD%A2%E5%BC%8F"><span class="nav-text">2.4 感知机的对偶形式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-5-%E7%AE%97%E6%B3%95%E7%9A%84%E6%94%B6%E6%95%9B%E6%80%A7"><span class="nav-text">2.5 算法的收敛性</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-K%E8%BF%91%E9%82%BB"><span class="nav-text">3. K近邻</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#3-1-K%E8%BF%91%E9%82%BB%E7%9B%B8%E5%85%B3%E6%A6%82%E5%BF%B5"><span class="nav-text">3.1 K近邻相关概念</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-2-K%E8%BF%91%E9%82%BB%E4%B8%89%E8%A6%81%E7%B4%A0"><span class="nav-text">3.2 K近邻三要素</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-1-K%E8%BF%91%E9%82%BB%E6%A8%A1%E5%9E%8B"><span class="nav-text">3.2.1 K近邻模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-2-%E8%B7%9D%E7%A6%BB%E5%BA%A6%E9%87%8F"><span class="nav-text">3.2.2 距离度量</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-3-K%E5%80%BC%E7%9A%84%E9%80%89%E6%8B%A9"><span class="nav-text">3.2.3 K值的选择</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-2-4-%E5%88%86%E7%B1%BB%E5%86%B3%E7%AD%96%E8%A7%84%E5%88%99"><span class="nav-text">3.2.4 分类决策规则</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-3-%E6%9E%84%E9%80%A0KD%E6%A0%91"><span class="nav-text">3.3 构造KD树</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-4-%E6%90%9C%E7%B4%A2KD%E6%A0%91"><span class="nav-text">3.4 搜索KD树</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%B3%95"><span class="nav-text">4. 朴素贝叶斯法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#4-1-%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%AE%9A%E7%90%86"><span class="nav-text">4.1 贝叶斯定理</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-2-%E4%BD%95%E4%B8%BA%E6%9C%B4%E7%B4%A0"><span class="nav-text">4.2 何为朴素</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-3-%E5%90%8E%E9%AA%8C%E6%A6%82%E7%8E%87%E6%9C%80%E5%A4%A7%E5%8C%96"><span class="nav-text">4.3 后验概率最大化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-4-%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1"><span class="nav-text">4.4 极大似然估计</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-5-%E7%AE%97%E6%B3%95"><span class="nav-text">4.5 算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4-6-%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%B0%E8%AE%A1"><span class="nav-text">4.6 贝叶斯估计</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#5-%E5%86%B3%E7%AD%96%E6%A0%91"><span class="nav-text">5. 决策树</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#5-1-%E6%9D%A1%E4%BB%B6%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83"><span class="nav-text">5.1 条件概率分布</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-2-%E5%86%B3%E7%AD%96%E6%A0%91%E5%AD%A6%E4%B9%A0"><span class="nav-text">5.2 决策树学习</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-3-%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9"><span class="nav-text">5.3 特征选择</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-4-%E5%86%B3%E7%AD%96%E6%A0%91%E7%9A%84%E7%94%9F%E6%88%90"><span class="nav-text">5.4 决策树的生成</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#5-4-1-ID3%E7%AE%97%E6%B3%95"><span class="nav-text">5.4.1 ID3算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-4-2-C4-5%E7%AE%97%E6%B3%95"><span class="nav-text">5.4.2 C4.5算法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-5-%E5%89%AA%E6%9E%9D"><span class="nav-text">5.5 剪枝</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#5-5-1-%E9%A2%84%E5%89%AA%E6%9E%9D"><span class="nav-text">5.5.1 预剪枝</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-5-2-%E5%90%8E%E5%89%AA%E6%9E%9D"><span class="nav-text">5.5.2 后剪枝</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#5-5-2-1-%E9%99%8D%E4%BD%8E%E9%94%99%E8%AF%AF%E5%89%AA%E6%9E%9D-REP"><span class="nav-text">5.5.2.1 降低错误剪枝(REP)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-5-2-2-%E6%82%B2%E8%A7%82%E9%94%99%E8%AF%AF%E5%89%AA%E6%9E%9D-PEP"><span class="nav-text">5.5.2.2 悲观错误剪枝(PEP)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-5-2-3-%E6%9C%80%E5%B0%8F%E8%AF%AF%E5%B7%AE%E5%89%AA%E6%9E%9D-MEP"><span class="nav-text">5.5.2.3 最小误差剪枝(MEP)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-5-2-4-%E5%9F%BA%E4%BA%8E%E9%94%99%E8%AF%AF%E5%89%AA%E6%9E%9D-EBP"><span class="nav-text">5.5.2.4 基于错误剪枝(EBP)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-5-2-5-%E4%BB%A3%E4%BB%B7-%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%89%AA%E6%9E%9D-CCP"><span class="nav-text">5.5.2.5 代价-复杂度剪枝(CCP)</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5-6-CART%E7%AE%97%E6%B3%95"><span class="nav-text">5.6 CART算法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#5-6-1-%E6%A0%91%E7%9A%84%E7%94%9F%E6%88%90"><span class="nav-text">5.6.1 树的生成</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#5-6-1-1-%E5%88%86%E7%B1%BB%E6%A0%91"><span class="nav-text">5.6.1.1 分类树</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-6-1-2-%E5%9B%9E%E5%BD%92%E6%A0%91"><span class="nav-text">5.6.1.2 回归树</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-6-2-%E6%A0%91%E7%9A%84%E5%89%AA%E6%9E%9D"><span class="nav-text">5.6.2 树的剪枝</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#6-%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92"><span class="nav-text">6. 逻辑回归</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#7-%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B"><span class="nav-text">7. 最大熵模型</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#7-1-%E6%9C%80%E5%A4%A7%E7%86%B5%E5%8E%9F%E7%90%86"><span class="nav-text">7.1 最大熵原理</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#7-1-1-%E7%A6%BB%E6%95%A3%E5%88%86%E5%B8%83"><span class="nav-text">7.1.1 离散分布</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-1-2-%E8%BF%9E%E7%BB%AD%E5%88%86%E5%B8%83"><span class="nav-text">7.1.2 连续分布</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-2-%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B"><span class="nav-text">7.2 最大熵模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-3-%E5%AF%BB%E6%89%BE%E6%9C%80%E5%A4%A7%E6%9D%A1%E4%BB%B6%E7%86%B5"><span class="nav-text">7.3 寻找最大条件熵</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-4-%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%AD%A6%E4%B9%A0"><span class="nav-text">7.4 最大熵模型的学习</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-5-%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1"><span class="nav-text">7.5 极大似然估计</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7-6-%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95"><span class="nav-text">7.6 优化算法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#7-6-1-%E6%9C%80%E9%80%9F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95"><span class="nav-text">7.6.1 最速梯度下降法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-6-2-%E7%89%9B%E9%A1%BF%E6%B3%95"><span class="nav-text">7.6.2 牛顿法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#7-6-2-1-%E6%B1%82%E9%9B%B6%E7%82%B9"><span class="nav-text">7.6.2.1 求零点</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-6-2-1-%E6%B1%82%E6%9E%81%E5%B0%8F%E5%80%BC"><span class="nav-text">7.6.2.1 求极小值</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-6-3-%E6%8B%9F%E7%89%9B%E9%A1%BF%E6%B3%95"><span class="nav-text">7.6.3 拟牛顿法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#7-6-3-1-%E6%9D%A1%E4%BB%B6"><span class="nav-text">7.6.3.1 条件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-6-3-2-%E4%B8%80%E7%BB%B4%E6%90%9C%E7%B4%A2"><span class="nav-text">7.6.3.2 一维搜索</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-6-3-3-DFP%E7%AE%97%E6%B3%95"><span class="nav-text">7.6.3.3 DFP算法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-6-3-4-BFGS%E7%AE%97%E6%B3%95"><span class="nav-text">7.6.3.4 BFGS算法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-6-3-5-Broyden%E7%AE%97%E6%B3%95"><span class="nav-text">7.6.3.5 Broyden算法</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-6-4-%E8%BF%AD%E4%BB%A3%E5%B0%BA%E5%BA%A6%E6%B3%95"><span class="nav-text">7.6.4 迭代尺度法</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#8-%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA"><span class="nav-text">8. 支持向量机</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#8-1-%E7%BA%BF%E6%80%A7%E5%8F%AF%E5%88%86%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA"><span class="nav-text">8.1 线性可分支持向量机</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#8-1-1-%E5%8E%9F%E5%A7%8B%E7%AE%97%E6%B3%95"><span class="nav-text">8.1.1 原始算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-1-2-%E5%AF%B9%E5%81%B6%E7%AE%97%E6%B3%95"><span class="nav-text">8.1.2 对偶算法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#8-2-%E7%BA%BF%E6%80%A7%E4%B8%8D%E5%8F%AF%E5%88%86%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA"><span class="nav-text">8.2 线性不可分支持向量机</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#8-2-1-%E5%8E%9F%E5%A7%8B%E7%AE%97%E6%B3%95"><span class="nav-text">8.2.1 原始算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-2-2-%E5%AF%B9%E5%81%B6%E7%AE%97%E6%B3%95"><span class="nav-text">8.2.2 对偶算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-2-3-%E5%90%88%E9%A1%B5%E6%8D%9F%E5%A4%B1"><span class="nav-text">8.2.3 合页损失</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#8-3-%E9%9D%9E%E7%BA%BF%E6%80%A7%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA"><span class="nav-text">8.3 非线性支持向量机</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#8-3-1-%E6%A0%B8%E5%87%BD%E6%95%B0"><span class="nav-text">8.3.1 核函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-3-2-%E5%AE%9A%E4%B9%89%E5%9C%A8%E6%AC%A7%E6%B0%8F%E7%A9%BA%E9%97%B4%E7%9A%84%E6%AD%A3%E5%AE%9A%E6%A0%B8%E5%87%BD%E6%95%B0"><span class="nav-text">8.3.2 定义在欧氏空间的正定核函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-3-3-%E5%AE%9A%E4%B9%89%E5%9C%A8%E7%A6%BB%E6%95%A3%E6%95%B0%E6%8D%AE%E9%9B%86%E5%90%88%E7%9A%84%E6%AD%A3%E5%AE%9A%E6%A0%B8%E5%87%BD%E6%95%B0"><span class="nav-text">8.3.3 定义在离散数据集合的正定核函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-3-4-%E9%9D%9E%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA%E7%9A%84%E7%AE%97%E6%B3%95"><span class="nav-text">8.3.4 非支持向量机的算法</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#8-3-4-1-%E5%9D%90%E6%A0%87%E4%B8%8B%E9%99%8D%E6%B3%95"><span class="nav-text">8.3.4.1 坐标下降法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-3-4-2-SMO-%E5%BA%8F%E5%88%97%E6%9C%80%E5%B0%8F%E6%9C%80%E4%BC%98-%E7%AE%97%E6%B3%95"><span class="nav-text">8.3.4.2 SMO(序列最小最优)算法</span></a></li></ol></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="v5le0n9"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">v5le0n9</p>
  <div class="site-description" itemprop="description">v5le0n9's garden</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">48</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">9</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">20</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://blog.csdn.net/Leong_Vinson" title="CSDN → https:&#x2F;&#x2F;blog.csdn.net&#x2F;Leong_Vinson" rel="noopener" target="_blank"><i class="fab fa-cuttlefish fa-fw"></i>CSDN</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://github.com/v5le0n9" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;v5le0n9" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:v5le0n9@163.com" title="E-Mail → mailto:v5le0n9@163.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">v5le0n9</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
    <span title="站点总字数">951k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">14:25</span>
</div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

<script src="/js/bookmark.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">

<script>
NexT.utils.loadComments(document.querySelector('#gitalk-container'), () => {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js', () => {
    var gitalk = new Gitalk({
      clientID    : '7c58e80079a2457b610d',
      clientSecret: 'fc16b1b0fdfb278016ebe41c20f3743c3c927466',
      repo        : 'comments.github.io',
      owner       : 'v5le0n9',
      admin       : ['v5le0n9'],
      id          : '83cf7f3b58a09347b039dc6ef37fb403',
        language: 'zh-CN',
      distractionFreeMode: true
    });
    gitalk.render('gitalk-container');
  }, window.Gitalk);
});
</script>

</body>
</html>
